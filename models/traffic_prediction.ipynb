{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475205e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset preparation \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_timestamps():\n",
    "    start_date = datetime(2025, 4, 7, 15, 0, 0)  \n",
    "    days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    timestamps = []\n",
    "    for day_idx in range(7):\n",
    "        day_start = start_date + timedelta(days=day_idx)\n",
    "        for sec in range(1800): \n",
    "            timestamps.append((day_start + timedelta(seconds=sec), days[day_idx]))\n",
    "    return timestamps\n",
    "\n",
    "\n",
    "def generate_synthetic_dataset():\n",
    "    timestamps = generate_timestamps()  \n",
    "    data = {\n",
    "        'timestamp': [],\n",
    "        'day': [],\n",
    "        'red_light_in_less_than_60_sec': [],\n",
    "        'current_cctv_left': [],\n",
    "        'current_cctv_right': [],\n",
    "        'vehicles_in_60s_left': [],\n",
    "        'vehicles_in_60s_right': []\n",
    "    }\n",
    "\n",
    "    for ts, day in timestamps:\n",
    "        minute = ts.minute\n",
    "        is_weekday = day in [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]\n",
    "\n",
    "        for red_light in [\"Yes\", \"No\"]:\n",
    "            if is_weekday and 0 <= minute <= 5:  \n",
    "                current_left = np.random.randint(4, 6)  \n",
    "                current_right = np.random.randint(4, 6)\n",
    "            else:\n",
    "                current_left = np.random.randint(0, 3) if not is_weekday else np.random.randint(1, 3)\n",
    "                current_right = np.random.randint(0, 3) if not is_weekday else np.random.randint(1, 3)\n",
    "\n",
    "            if red_light == \"Yes\":\n",
    "                increase_left = np.random.randint(3, 7)\n",
    "                increase_right = np.random.randint(3, 7)\n",
    "                future_left = current_left + increase_left\n",
    "                future_right = current_right + increase_right\n",
    "            elif is_weekday and 0 <= minute <= 5:  \n",
    "                future_left = np.random.randint(7, 9)\n",
    "                future_right = np.random.randint(7, 9)\n",
    "            else:  \n",
    "                change_left = np.random.choice([0, 1, 2], p=[0.7, 0.2, 0.1])\n",
    "                change_right = np.random.choice([0, 1, 2], p=[0.7, 0.2, 0.1])\n",
    "                future_left = current_left + change_left\n",
    "                future_right = current_right + change_right\n",
    "\n",
    "            future_left = max(0, future_left)\n",
    "            future_right = max(0, future_right)\n",
    "\n",
    "            data['timestamp'].append(ts)\n",
    "            data['day'].append(day)\n",
    "            data['red_light_in_less_than_60_sec'].append(red_light)\n",
    "            data['current_cctv_left'].append(current_left)\n",
    "            data['current_cctv_right'].append(current_right)\n",
    "            data['vehicles_in_60s_left'].append(future_left)\n",
    "            data['vehicles_in_60s_right'].append(future_right)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def split_dataset(df):\n",
    "    total_size = len(df)\n",
    "    train_size = int(total_size * 0.7)  \n",
    "    valid_size = int(total_size * 0.15)  \n",
    "    test_size = total_size - train_size - valid_size  \n",
    "\n",
    "    df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    train_df = df_shuffled.iloc[:train_size]\n",
    "    valid_df = df_shuffled.iloc[train_size:train_size + valid_size]\n",
    "    test_df = df_shuffled.iloc[train_size + valid_size:]\n",
    "\n",
    "    return train_df, valid_df, test_df\n",
    "\n",
    "dataset = generate_synthetic_dataset()\n",
    "train_df, valid_df, test_df = split_dataset(dataset)\n",
    "\n",
    "train_df.to_csv(\"/content/train_dataset_7days_3pm_330pm_25200.csv\", index=False)\n",
    "valid_df.to_csv(\"/content/valid_dataset_7days_3pm_330pm_25200.csv\", index=False)\n",
    "test_df.to_csv(\"/content/test_dataset_7days_3pm_330pm_25200.csv\", index=False)\n",
    "\n",
    "print(\"Training Data Sample:\\n\", train_df.head())\n",
    "print(\"\\nValidation Data Sample:\\n\", valid_df.head())\n",
    "print(\"\\nTest Data Sample:\\n\", test_df.head())\n",
    "print(\"\\nDataset Sizes:\")\n",
    "print(f\"Train: {len(train_df)}, Validation: {len(valid_df)}, Test: {len(test_df)}\")\n",
    "print(\"\\nRed Light Distribution in Full Dataset:\")\n",
    "print(dataset['red_light_in_less_than_60_sec'].value_counts())\n",
    "print(\"\\nDay Distribution in Full Dataset:\")\n",
    "print(dataset['day'].value_counts())\n",
    "print(\"\\nTimestamp Range Check:\")\n",
    "print(f\"Min: {dataset['timestamp'].min()}, Max: {dataset['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9607063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Concatenate, Lambda, Multiply\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import KFold\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    print(f\"GPU devices available: {len(physical_devices)}\")\n",
    "    try:\n",
    "        for device in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(device, True)\n",
    "        print(\"Using GPU for training with memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Memory growth setting error: {e}\")\n",
    "else:\n",
    "    print(\"No GPU available, using CPU\")\n",
    "\n",
    "train_df = pd.read_csv(\"/content/train_dataset_7days_3pm_330pm_25200.csv\")\n",
    "valid_df = pd.read_csv(\"/content/valid_dataset_7days_3pm_330pm_25200.csv\")\n",
    "\n",
    "le_day = LabelEncoder()\n",
    "train_df['day'] = le_day.fit_transform(train_df['day'])\n",
    "valid_df['day'] = le_day.transform(valid_df['day'])\n",
    "train_df['red_light_in_less_than_60_sec'] = train_df['red_light_in_less_than_60_sec'].map({'Yes': 1, 'No': 0})\n",
    "valid_df['red_light_in_less_than_60_sec'] = valid_df['red_light_in_less_than_60_sec'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "train_df['red_light_importance'] = train_df['red_light_in_less_than_60_sec'] * 3\n",
    "valid_df['red_light_importance'] = valid_df['red_light_in_less_than_60_sec'] * 3\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features = ['current_cctv_left', 'current_cctv_right', 'day', 'red_light_in_less_than_60_sec', 'red_light_importance']\n",
    "target = ['vehicles_in_60s_left', 'vehicles_in_60s_right']\n",
    "train_scaled = scaler.fit_transform(train_df[features + target])\n",
    "valid_scaled = scaler.transform(valid_df[features + target])\n",
    "\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(le_day, 'label_encoder_day.pkl')\n",
    "\n",
    "def create_sequences(data, lookback=10):\n",
    "    X, y = [], []\n",
    "    for i in range(lookback, len(data)):\n",
    "        X.append(data[i-lookback:i, :len(features)])\n",
    "        y.append(data[i, len(features):])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "lookback = 10\n",
    "X_train, y_train = create_sequences(train_scaled)\n",
    "X_valid, y_valid = create_sequences(valid_scaled)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}, y_valid shape: {y_valid.shape}\")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
    "callbacks = [early_stopping, model_checkpoint]\n",
    "\n",
    "def create_lstm_model_with_red_light_attention(input_shape):\n",
    "    main_input = Input(shape=input_shape)\n",
    "    red_light_lambda = Lambda(lambda x: x[:, :, 3:4])(main_input)\n",
    "    lstm1 = LSTM(64,\n",
    "                 return_sequences=True,\n",
    "                 activation='tanh',\n",
    "                 recurrent_activation='sigmoid',\n",
    "                 recurrent_dropout=0.0,\n",
    "                 unroll=False,\n",
    "                 use_bias=True)(main_input)\n",
    "    lstm1_dropout = Dropout(0.2)(lstm1)\n",
    "    lstm2 = LSTM(32,\n",
    "                 activation='tanh',\n",
    "                 recurrent_activation='sigmoid',\n",
    "                 recurrent_dropout=0.0,\n",
    "                 unroll=False,\n",
    "                 use_bias=True)(lstm1_dropout)\n",
    "    lstm2_dropout = Dropout(0.2)(lstm2)\n",
    "    red_light_attention = Lambda(lambda x: x[:, -1:, 0])(red_light_lambda)\n",
    "    red_light_attention = Dense(32, activation='sigmoid')(red_light_attention)\n",
    "    weighted_features = Multiply()([lstm2_dropout, red_light_attention])\n",
    "    combined = Concatenate()([lstm2_dropout, weighted_features])\n",
    "    dense1 = Dense(32, activation='relu')(combined)\n",
    "    dropout = Dropout(0.2)(dense1)\n",
    "    dense2 = Dense(16, activation='relu')(dropout)\n",
    "    output = Dense(2)(dense2)\n",
    "    model = Model(inputs=main_input, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y_true - y_pred)))\n",
    "\n",
    "def analyze_red_light_impact(model, X, y):\n",
    "    red_light_indices = [i for i in range(len(X)) if X[i, -1, 3] > 0.5]\n",
    "    no_red_light_indices = [i for i in range(len(X)) if X[i, -1, 3] <= 0.5]\n",
    "    all_preds = model.predict(X, verbose=0)\n",
    "    red_light_rmse = calculate_rmse(y[red_light_indices], all_preds[red_light_indices]) if len(red_light_indices) > 0 else None\n",
    "    no_red_light_rmse = calculate_rmse(y[no_red_light_indices], all_preds[no_red_light_indices]) if len(no_red_light_indices) > 0 else None\n",
    "    return {\n",
    "        'red_light_count': len(red_light_indices),\n",
    "        'no_red_light_count': len(no_red_light_indices),\n",
    "        'red_light_rmse': red_light_rmse,\n",
    "        'no_red_light_rmse': no_red_light_rmse\n",
    "    }\n",
    "\n",
    "num_models = 3\n",
    "ensemble_models = []\n",
    "fold_histories = []\n",
    "all_train_rmse = []\n",
    "all_val_rmse = []\n",
    "\n",
    "print(\"Training ensemble of models with enhanced red light feature importance...\")\n",
    "for model_idx in range(num_models):\n",
    "    print(f\"\\nTraining model {model_idx+1}/{num_models}\")\n",
    "    model = create_lstm_model_with_red_light_attention((lookback, len(features)))\n",
    "    if model_idx == 0:\n",
    "        X_train_model, y_train_model = X_train, y_train\n",
    "    elif model_idx == 1:\n",
    "        X_train_model = X_train + np.random.normal(0, 0.01, X_train.shape)\n",
    "        y_train_model = y_train\n",
    "        X_train_model[:, :, 3] *= 1.5\n",
    "    else:\n",
    "        red_light_samples = [i for i in range(len(X_train)) if X_train[i, -1, 3] > 0.5]\n",
    "        non_red_light_samples = [i for i in range(len(X_train)) if X_train[i, -1, 3] <= 0.5]\n",
    "        if len(red_light_samples) > 0 and len(non_red_light_samples) > 0:\n",
    "            red_light_samples = np.random.choice(red_light_samples, size=min(len(red_light_samples)*2, len(non_red_light_samples)), replace=len(red_light_samples)*2 > len(red_light_samples))\n",
    "            non_red_light_samples = np.random.choice(non_red_light_samples, size=len(red_light_samples), replace=False)\n",
    "            balanced_indices = np.concatenate([red_light_samples, non_red_light_samples])\n",
    "            np.random.shuffle(balanced_indices)\n",
    "            X_train_model = X_train[balanced_indices]\n",
    "            y_train_model = y_train[balanced_indices]\n",
    "        else:\n",
    "            X_train_model, y_train_model = X_train, y_train\n",
    "    train_rmse = []\n",
    "    val_rmse = []\n",
    "    class RMSECallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            train_pred = self.model.predict(X_train_model, verbose=0)\n",
    "            train_rmse_val = calculate_rmse(y_train_model, train_pred)\n",
    "            train_rmse.append(train_rmse_val)\n",
    "            val_pred = self.model.predict(X_valid, verbose=0)\n",
    "            val_rmse_val = calculate_rmse(y_valid, val_pred)\n",
    "            val_rmse.append(val_rmse_val)\n",
    "            if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "                impact = analyze_red_light_impact(self.model, X_valid, y_valid)\n",
    "                print(f\"Red light analysis - Cases with red light: {impact['red_light_count']}, RMSE: {impact['red_light_rmse']:.4f}, Cases without: {impact['no_red_light_count']}, RMSE: {impact['no_red_light_rmse']:.4f}\")\n",
    "            print(f\"Epoch {epoch+1}: Train RMSE = {train_rmse_val:.4f}, Val RMSE = {val_rmse_val:.4f}\")\n",
    "    callbacks_with_rmse = callbacks + [RMSECallback()]\n",
    "    history = model.fit(\n",
    "        X_train_model, y_train_model,\n",
    "        epochs=15,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        callbacks=callbacks_with_rmse,\n",
    "        verbose=1\n",
    "    )\n",
    "    model.save(f\"lstm_traffic_model_{model_idx}.h5\")\n",
    "    ensemble_models.append(model)\n",
    "    history_dict = history.history\n",
    "    history_dict['train_rmse'] = train_rmse\n",
    "    history_dict['val_rmse'] = val_rmse\n",
    "    fold_histories.append(history_dict)\n",
    "    all_train_rmse.append(train_rmse)\n",
    "    all_val_rmse.append(val_rmse)\n",
    "    impact = analyze_red_light_impact(model, X_valid, y_valid)\n",
    "    print(f\"\\nFinal Red Light Impact Analysis for Model {model_idx+1}:\")\n",
    "    print(f\"- Cases with red light: {impact['red_light_count']}, RMSE: {impact['red_light_rmse']:.4f}\")\n",
    "    print(f\"- Cases without red light: {impact['no_red_light_count']}, RMSE: {impact['no_red_light_rmse']:.4f}\")\n",
    "    print(f\"Model {model_idx+1} final validation RMSE: {val_rmse[-1]:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(18, 15))\n",
    "plt.subplot(3, 2, 1)\n",
    "for i, history in enumerate(fold_histories):\n",
    "    plt.plot(history['loss'], linestyle='--', label=f'Model {i+1} train loss')\n",
    "    plt.plot(history['val_loss'], label=f'Model {i+1} val loss')\n",
    "plt.title('Mean Squared Error Loss for Each Model')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.subplot(3, 2, 2)\n",
    "for i in range(len(ensemble_models)):\n",
    "    plt.plot(all_train_rmse[i], linestyle='--', label=f'Model {i+1} train RMSE')\n",
    "    plt.plot(all_val_rmse[i], label=f'Model {i+1} val RMSE')\n",
    "plt.title('Root Mean Squared Error for Each Model')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.subplot(3, 2, 3)\n",
    "all_model_preds = [model.predict(X_valid[:100], verbose=0) for model in ensemble_models]\n",
    "ensemble_preds = np.mean(all_model_preds, axis=0)\n",
    "plt.scatter(range(100), y_valid[:100, 0], color='blue', label='Actual Left', alpha=0.7)\n",
    "plt.scatter(range(100), ensemble_preds[:100, 0], color='red', label='Predicted Left', alpha=0.7)\n",
    "plt.title('Ensemble Predictions vs Actual (Left Vehicles)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Normalized Vehicle Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.scatter(range(100), y_valid[:100, 1], color='green', label='Actual Right', alpha=0.7)\n",
    "plt.scatter(range(100), ensemble_preds[:100, 1], color='orange', label='Predicted Right', alpha=0.7)\n",
    "plt.title('Ensemble Predictions vs Actual (Right Vehicles)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Normalized Vehicle Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.subplot(3, 2, 5)\n",
    "red_light_indices = [i for i in range(len(X_valid)) if X_valid[i, -1, 3] > 0.5]\n",
    "no_red_light_indices = [i for i in range(len(X_valid)) if X_valid[i, -1, 3] <= 0.5]\n",
    "all_preds = np.array([model.predict(X_valid, verbose=0) for model in ensemble_models])\n",
    "ensemble_preds_all = np.mean(all_preds, axis=0)\n",
    "if len(red_light_indices) > 0:\n",
    "    red_light_errors = np.sqrt(np.mean(np.square(y_valid[red_light_indices] - ensemble_preds_all[red_light_indices]), axis=1))\n",
    "    plt.hist(red_light_errors, alpha=0.7, bins=20, color='red', label='Red Light Errors')\n",
    "if len(no_red_light_indices) > 0:\n",
    "    no_red_light_errors = np.sqrt(np.mean(np.square(y_valid[no_red_light_indices] - ensemble_preds_all[no_red_light_indices]), axis=1))\n",
    "    plt.hist(no_red_light_errors, alpha=0.7, bins=20, color='green', label='No Red Light Errors')\n",
    "plt.title('Error Distribution by Red Light Status')\n",
    "plt.xlabel('Prediction Error (RMSE)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.subplot(3, 2, 6)\n",
    "if len(red_light_indices) > 0:\n",
    "    red_light_y = y_valid[red_light_indices].flatten()\n",
    "    red_light_pred = ensemble_preds_all[red_light_indices].flatten()\n",
    "    plt.scatter(red_light_y, red_light_pred, color='red', alpha=0.5, label='Red Light')\n",
    "if len(no_red_light_indices) > 0:\n",
    "    no_red_light_y = y_valid[no_red_light_indices].flatten()\n",
    "    no_red_light_pred = ensemble_preds_all[no_red_light_indices].flatten()\n",
    "    plt.scatter(no_red_light_y, no_red_light_pred, color='green', alpha=0.5, label='No Red Light')\n",
    "max_val = max(np.max(y_valid), np.max(ensemble_preds_all))\n",
    "min_val = min(np.min(y_valid), np.min(ensemble_preds_all))\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'k--')\n",
    "plt.title('Actual vs Predicted by Red Light Status')\n",
    "plt.xlabel('Actual Value')\n",
    "plt.ylabel('Predicted Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('enhanced_red_light_metrics.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "def test_ensemble_model():\n",
    "    try:\n",
    "        scaler = joblib.load(\"scaler.pkl\")\n",
    "        le_day = joblib.load(\"label_encoder_day.pkl\")\n",
    "        model_paths = [f\"lstm_traffic_model_{i}.h5\" for i in range(num_models)]\n",
    "        models = [load_model(path) for path in model_paths]\n",
    "        print(f\"✅ {len(models)} models, scaler, and label encoder loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading models or preprocessors: {e}\")\n",
    "        return None\n",
    "    def preprocess_input(timestamp_str, day, red_light, current_left, current_right, lookback=10):\n",
    "        try:\n",
    "            timestamp = datetime.strptime(timestamp_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "            day_encoded = le_day.transform([day])[0]\n",
    "            red_light_encoded = 1 if red_light.lower() == \"yes\" else 0\n",
    "            red_light_importance = red_light_encoded * 3\n",
    "            input_data = [current_left, current_right, day_encoded, red_light_encoded, red_light_importance]\n",
    "            print(f\"📝 Raw input data: {input_data}\")\n",
    "            print(f\"🚦 Red light status: {'YES (Important)' if red_light_encoded == 1 else 'NO'}\")\n",
    "            sequence = np.array([input_data] * lookback)\n",
    "            dummy_target = [0, 0]\n",
    "            sequence_with_dummy = np.hstack((sequence, np.array([dummy_target] * lookback)))\n",
    "            scaled_sequence = scaler.transform(sequence_with_dummy)\n",
    "            scaled_sequence = scaled_sequence[:, :len(input_data)]\n",
    "            print(f\"📊 Scaled sequence shape: {scaled_sequence.shape}\")\n",
    "            return np.expand_dims(scaled_sequence, axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in preprocessing: {e}\")\n",
    "            return None\n",
    "    def predict_traffic(timestamp_str, day, red_light, current_left, current_right):\n",
    "        X_test = preprocess_input(timestamp_str, day, red_light, current_left, current_right)\n",
    "        if X_test is None:\n",
    "            return None\n",
    "        try:\n",
    "            predictions = [model.predict(X_test, verbose=0) for model in models]\n",
    "            for i, pred in enumerate(predictions):\n",
    "                print(f\"Model {i+1} prediction: {pred[0]}\")\n",
    "            pred_scaled = np.mean(predictions, axis=0)\n",
    "            print(f\"🔢 Ensemble scaled prediction: {pred_scaled}\")\n",
    "            dummy_features = np.zeros((1, 5))\n",
    "            pred_with_dummy = np.hstack((dummy_features, pred_scaled))\n",
    "            pred = scaler.inverse_transform(pred_with_dummy)[:, 5:]\n",
    "            return pred[0]\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in prediction: {e}\")\n",
    "            return None\n",
    "    print(\"\\n----- TESTING WITH RED LIGHT = YES -----\")\n",
    "    prediction_red = predict_traffic(\"2025-04-07 15:03:22\", \"Monday\", \"Yes\", 5, 4)\n",
    "    print(\"\\n----- TESTING WITH RED LIGHT = NO -----\")\n",
    "    prediction_no_red = predict_traffic(\"2025-04-07 15:03:22\", \"Monday\", \"No\", 5, 4)\n",
    "    if prediction_red is not None and prediction_no_red is not None:\n",
    "        print(\"\\n----- IMPACT OF RED LIGHT ON PREDICTIONS -----\")\n",
    "        print(f\"🚦 WITH Red Light: Left={prediction_red[0]:.1f}, Right={prediction_red[1]:.1f}\")\n",
    "        print(f\"🚦 WITHOUT Red Light: Left={prediction_no_red[0]:.1f}, Right={prediction_no_red[1]:.1f}\")\n",
    "        print(f\"🔄 Difference: Left={prediction_red[0]-prediction_no_red[0]:.1f}, Right={prediction_red[1]-prediction_no_red[1]:.1f}\")\n",
    "    return prediction_red\n",
    "\n",
    "print(\"\\n----- TESTING ENSEMBLE MODEL WITH ENHANCED RED LIGHT FEATURE -----\")\n",
    "test_ensemble_model()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

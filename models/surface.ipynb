{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe007f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from timm.models import efficientnet_b2\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import re\n",
    "import io\n",
    "import json\n",
    "\n",
    "GPU_INDEX = 0\n",
    "\n",
    "CONFIG = {\n",
    "    'data_root': 'ABC(RSCD)/Balanced_RSCD_Dataset',\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 20,\n",
    "    'learning_rate': 2e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'num_workers': 8,\n",
    "    'device': torch.device(f'cuda:{GPU_INDEX}' if torch.cuda.is_available() else 'cpu'),\n",
    "    'log_interval': 50,\n",
    "    'resume_checkpoint': None\n",
    "}\n",
    "\n",
    "CONFIG['checkpoint_dir'] = os.path.join(CONFIG['data_root'], 'checkpoints2')\n",
    "CONFIG['plots_dir'] = os.path.join(CONFIG['data_root'], 'plots')\n",
    "\n",
    "os.makedirs(CONFIG['checkpoint_dir'], exist_ok=True)\n",
    "os.makedirs(CONFIG['plots_dir'], exist_ok=True)\n",
    "\n",
    "class RoadSurfaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, split, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        self.idx_to_class = {}\n",
    "        self.corrupted_images = 0\n",
    "        \n",
    "        def extract_label(filename):\n",
    "            parts = filename.split('-')\n",
    "            for i, part in enumerate(parts):\n",
    "                if part[0].isdigit():\n",
    "                    label = '-'.join(parts[i+1:]).split('.')[0]\n",
    "                    return label.replace('-', '_')\n",
    "            return None\n",
    "\n",
    "        train_dir = os.path.join(root_dir, 'train')\n",
    "        class_folders = sorted([d for d in os.listdir(train_dir) \n",
    "                        if os.path.isdir(os.path.join(train_dir, d))])\n",
    "        \n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(class_folders)}\n",
    "        self.idx_to_class = {i: cls_name for i, cls_name in enumerate(class_folders)}\n",
    "        \n",
    "        if split == 'train':\n",
    "            for class_name in class_folders:\n",
    "                class_dir = os.path.join(train_dir, class_name)\n",
    "                class_idx = self.class_to_idx[class_name]\n",
    "                \n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        img_path = os.path.join(class_dir, img_name)\n",
    "                        self.samples.append((img_path, class_idx))\n",
    "        else:\n",
    "            split_dir = os.path.join(root_dir, split)\n",
    "            \n",
    "            for img_name in os.listdir(split_dir):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(split_dir, img_name)\n",
    "                    \n",
    "                    extracted_label = extract_label(img_name)\n",
    "                    \n",
    "                    if extracted_label in self.class_to_idx:\n",
    "                        class_idx = self.class_to_idx[extracted_label]\n",
    "                        self.samples.append((img_path, class_idx))\n",
    "                    else:\n",
    "                        print(f\"Warning: Unknown label '{extracted_label}' in {img_name}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "            try:\n",
    "                img_path, class_idx = self.samples[idx]\n",
    "                \n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                \n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                \n",
    "                return image, class_idx\n",
    "            \n",
    "            except (UnidentifiedImageError, IOError) as e:\n",
    "                print(f\"Corrupted image found: {img_path}\")\n",
    "                self.corrupted_images += 1\n",
    "                \n",
    "                idx = (idx + 1) % len(self.samples)\n",
    "    \n",
    "    def get_corrupted_image_count(self):\n",
    "        return self.corrupted_images\n",
    "\n",
    "def find_latest_checkpoint(checkpoint_dir):\n",
    "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith('epoch_') and f.endswith('_checkpoint.pth')]\n",
    "    if not checkpoints:\n",
    "        return None\n",
    "    \n",
    "    latest_checkpoint = sorted(checkpoints, key=lambda x: int(x.split('_')[1]))[-1]\n",
    "    return os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "\n",
    "def verify_dataset_structure():\n",
    "    train_dir = os.path.join(CONFIG['data_root'], 'train')\n",
    "    val_dir = os.path.join(CONFIG['data_root'], 'vali_20k')\n",
    "    test_dir = os.path.join(CONFIG['data_root'], 'test_50k')\n",
    "    \n",
    "    for dir_path, dir_name in [(train_dir, 'train'), (val_dir, 'vali_20k'), (test_dir, 'test_50k')]:\n",
    "        if not os.path.exists(dir_path):\n",
    "            print(f\"ERROR: Directory not found: {dir_path}\")\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"Found directory: {dir_name}\")\n",
    "    \n",
    "    class_folders = sorted([d for d in os.listdir(train_dir) \n",
    "                     if os.path.isdir(os.path.join(train_dir, d))])\n",
    "    \n",
    "    if not class_folders:\n",
    "        print(f\"ERROR: No class folders found in {train_dir}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"Found {len(class_folders)} classes in the training directory:\")\n",
    "    for i, class_name in enumerate(class_folders):\n",
    "        class_path = os.path.join(train_dir, class_name)\n",
    "        num_samples = len([f for f in os.listdir(class_path) \n",
    "                          if os.path.isfile(os.path.join(class_path, f)) and\n",
    "                          f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        print(f\"  {i+1}. {class_name}: {num_samples} samples\")\n",
    "    \n",
    "    for dir_path, dir_name in [(val_dir, 'vali_20k'), (test_dir, 'test_50k')]:\n",
    "        num_samples = len([f for f in os.listdir(dir_path) \n",
    "                         if os.path.isfile(os.path.join(dir_path, f)) and \n",
    "                         f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        print(f\"{dir_name}: {num_samples} samples\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def get_transforms():\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=0.2)\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "def get_datasets_and_loaders():\n",
    "    train_transform, val_transform = get_transforms()\n",
    "    \n",
    "    train_dataset = RoadSurfaceDataset(\n",
    "        root_dir=CONFIG['data_root'],\n",
    "        split='train',\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = RoadSurfaceDataset(\n",
    "        root_dir=CONFIG['data_root'],\n",
    "        split='vali_20k',\n",
    "        transform=val_transform\n",
    "    )\n",
    "    \n",
    "    test_dataset = RoadSurfaceDataset(\n",
    "        root_dir=CONFIG['data_root'],\n",
    "        split='test_50k',\n",
    "        transform=val_transform\n",
    "    )\n",
    "    \n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_dataset.idx_to_class\n",
    "\n",
    "def create_model(num_classes):\n",
    "    model = efficientnet_b2(pretrained=True)\n",
    "    \n",
    "    in_features = model.classifier.in_features\n",
    "    \n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(in_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.classes = classes\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.classes - 1))\n",
    "            true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n",
    "        \n",
    "        return torch.mean(torch.sum(-true_dist * self.log_softmax(pred), dim=1))\n",
    "\n",
    "class TrainingHistory:\n",
    "    def __init__(self, save_dir):\n",
    "        self.save_dir = save_dir\n",
    "        self.train_losses = []\n",
    "        self.train_accs = []\n",
    "        self.val_losses = []\n",
    "        self.val_accs = []\n",
    "        self.lr_history = []\n",
    "        \n",
    "    def update(self, train_loss, train_acc, val_loss, val_acc, learning_rate):\n",
    "        self.train_losses.append(train_loss)\n",
    "        self.train_accs.append(train_acc)\n",
    "        self.val_losses.append(val_loss)\n",
    "        self.val_accs.append(val_acc)\n",
    "        self.lr_history.append(learning_rate)\n",
    "        \n",
    "    def plot(self):\n",
    "        epochs = range(1, len(self.train_losses) + 1)\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(epochs, self.train_losses, 'b-', label='Training Loss')\n",
    "        plt.plot(epochs, self.val_losses, 'r-', label='Validation Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(epochs, self.train_accs, 'b-', label='Training Accuracy')\n",
    "        plt.plot(epochs, self.val_accs, 'r-', label='Validation Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(epochs, self.lr_history, 'g-')\n",
    "        plt.title('Learning Rate over Time')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.save_dir, 'training_history.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        history_data = {\n",
    "            'train_losses': self.train_losses,\n",
    "            'train_accs': self.train_accs,\n",
    "            'val_losses': self.val_losses,\n",
    "            'val_accs': self.val_accs,\n",
    "            'lr_history': self.lr_history\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(self.save_dir, 'training_history.json'), 'w') as f:\n",
    "            json.dump(history_data, f)\n",
    "\n",
    "def train_model():\n",
    "    if not verify_dataset_structure():\n",
    "        print(\"Dataset verification failed. Please check your directory structure.\")\n",
    "        return\n",
    "    \n",
    "    train_loader, val_loader, test_loader, idx_to_class = get_datasets_and_loaders()\n",
    "    num_classes = len(idx_to_class)\n",
    "    \n",
    "    model = create_model(num_classes)\n",
    "    model = model.to(CONFIG['device'])\n",
    "    \n",
    "    criterion = LabelSmoothingLoss(classes=num_classes, smoothing=0.1)\n",
    "    \n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CONFIG['learning_rate'],\n",
    "        weight_decay=CONFIG['weight_decay']\n",
    "    )\n",
    "    \n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=CONFIG['learning_rate'],\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        epochs=CONFIG['num_epochs'],\n",
    "        pct_start=0.3\n",
    "    )\n",
    "    \n",
    "    history = TrainingHistory(CONFIG['plots_dir'])\n",
    "    \n",
    "    start_epoch = 0\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    if CONFIG['resume_checkpoint'] and os.path.exists(CONFIG['resume_checkpoint']):\n",
    "        print(f\"Resuming from checkpoint: {CONFIG['resume_checkpoint']}\")\n",
    "        checkpoint = torch.load(CONFIG['resume_checkpoint'], map_location=CONFIG['device'])\n",
    "        \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        if 'optimizer_state_dict' in checkpoint:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        if 'scheduler_state_dict' in checkpoint:\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        \n",
    "        start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "        best_val_acc = checkpoint.get('best_val_acc', 0.0)\n",
    "        \n",
    "        if 'history' in checkpoint:\n",
    "            history.train_losses = checkpoint['history'].get('train_losses', [])\n",
    "            history.train_accs = checkpoint['history'].get('train_accs', [])\n",
    "            history.val_losses = checkpoint['history'].get('val_losses', [])\n",
    "            history.val_accs = checkpoint['history'].get('val_accs', [])\n",
    "            history.lr_history = checkpoint['history'].get('lr_history', [])\n",
    "        \n",
    "        print(f\"Resuming from epoch {start_epoch} with best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    train_dataset = train_loader.dataset\n",
    "    if hasattr(train_dataset, 'get_corrupted_image_count'):\n",
    "        corrupted_count = train_dataset.get_corrupted_image_count()\n",
    "        if corrupted_count > 0:\n",
    "            print(f\"Warning: {corrupted_count} corrupted images were skipped during training\")\n",
    "    \n",
    "    print(f\"Training on {CONFIG['device']}\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(f\"Model: EfficientNet-B2 with custom classifier\")\n",
    "    print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "    print(f\"Learning rate: {CONFIG['learning_rate']}\")\n",
    "    print(f\"Weight decay: {CONFIG['weight_decay']}\")\n",
    "    print(\"Class Mapping:\")\n",
    "    for idx, cls_name in idx_to_class.items():\n",
    "        print(f\"  {idx}: {cls_name}\")\n",
    "    \n",
    "    for epoch in range(start_epoch, CONFIG['num_epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        batch_time = AverageMeter()\n",
    "        \n",
    "        end = time.time()\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(CONFIG['device']), targets.to(CONFIG['device'])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += targets.size(0)\n",
    "            train_correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            if (batch_idx + 1) % CONFIG['log_interval'] == 0:\n",
    "                print(f\"Batch: {batch_idx+1}/{len(train_loader)} | \"\n",
    "                      f\"Loss: {train_loss/(batch_idx+1):.4f} | \"\n",
    "                      f\"Acc: {100.*train_correct/train_total:.2f}% | \"\n",
    "                      f\"Time: {batch_time.avg:.3f}s/batch | \"\n",
    "                      f\"LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "        \n",
    "        train_loss = train_loss/len(train_loader)\n",
    "        train_acc = 100. * train_correct / train_total\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        class_correct = [0] * num_classes\n",
    "        class_total = [0] * num_classes\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(CONFIG['device']), targets.to(CONFIG['device'])\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += predicted.eq(targets).sum().item()\n",
    "                \n",
    "                for i in range(targets.size(0)):\n",
    "                    label = targets[i].item()\n",
    "                    class_total[label] += 1\n",
    "                    if predicted[i].item() == label:\n",
    "                        class_correct[label] += 1\n",
    "        \n",
    "        val_loss = val_loss/len(val_loader)\n",
    "        val_acc = 100. * val_correct / val_total\n",
    "        \n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        history.update(train_loss, train_acc, val_loss, val_acc, current_lr)\n",
    "        history.plot()\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | \"\n",
    "              f\"Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        class_accuracies = [(i, 100.0 * class_correct[i] / max(1, class_total[i])) for i in range(num_classes)]\n",
    "        worst_classes = sorted(class_accuracies, key=lambda x: x[1])[:3]\n",
    "        print(\"Worst performing classes:\")\n",
    "        for idx, acc in worst_classes:\n",
    "            print(f\"  {idx_to_class[idx]}: {acc:.2f}%\")\n",
    "        \n",
    "        is_best = val_acc > best_val_acc\n",
    "        if is_best:\n",
    "            best_val_acc = val_acc\n",
    "            print(f\"New best validation accuracy: {best_val_acc:.2f}%\")\n",
    "            \n",
    "            best_model_path = os.path.join(CONFIG['checkpoint_dir'], 'best_model.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'train_acc': train_acc,\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'class_mapping': idx_to_class,\n",
    "                'history': {\n",
    "                    'train_losses': history.train_losses,\n",
    "                    'train_accs': history.train_accs,\n",
    "                    'val_losses': history.val_losses,\n",
    "                    'val_accs': history.val_accs,\n",
    "                    'lr_history': history.lr_history\n",
    "                }\n",
    "            }, best_model_path)\n",
    "            print(f\"Best model saved to {best_model_path}\")\n",
    "        \n",
    "        epoch_checkpoint_path = os.path.join(CONFIG['checkpoint_dir'], f'epoch_{epoch+1}_checkpoint.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'class_mapping': idx_to_class,\n",
    "            'history': {\n",
    "                'train_losses': history.train_losses,\n",
    "                'train_accs': history.train_accs,\n",
    "                'val_losses': history.val_losses,\n",
    "                'val_accs': history.val_accs,\n",
    "                'lr_history': history.lr_history\n",
    "            }\n",
    "        }, epoch_checkpoint_path)\n",
    "        print(f\"Checkpoint saved to {epoch_checkpoint_path}\")\n",
    "    \n",
    "    final_model_path = os.path.join(CONFIG['checkpoint_dir'], 'final_model.pth')\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'class_mapping': idx_to_class,\n",
    "        'best_val_acc': best_val_acc\n",
    "    }, final_model_path)\n",
    "    print(f\"\\nFinal model saved to {final_model_path}\")\n",
    "    \n",
    "    best_model_path = os.path.join(CONFIG['checkpoint_dir'], 'best_model.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(\"\\nLoading best model for test evaluation...\")\n",
    "        checkpoint = torch.load(best_model_path, map_location=CONFIG['device'])\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    class_correct = [0] * num_classes\n",
    "    class_total = [0] * num_classes\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(CONFIG['device']), targets.to(CONFIG['device'])\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_total += targets.size(0)\n",
    "            test_correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            for i in range(targets.size(0)):\n",
    "                label = targets[i].item()\n",
    "                class_total[label] += 1\n",
    "                if predicted[i].item() == label:\n",
    "                    class_correct[label] += 1\n",
    "    \n",
    "    test_acc = 100. * test_correct / test_total\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    print(\"\\nPer-class test accuracy:\")\n",
    "    for i in range(num_classes):\n",
    "        if class_total[i] > 0:\n",
    "            class_acc = 100.0 * class_correct[i] / class_total[i]\n",
    "            print(f\"  {idx_to_class[i]}: {class_acc:.2f}% ({class_correct[i]}/{class_total[i]})\")\n",
    "    \n",
    "    print(\"\\nTraining completed!\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Final test accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def plot_prediction_examples(model, test_loader, idx_to_class, num_examples=5):\n",
    "    model.eval()\n",
    "    \n",
    "    plt.figure(figsize=(20, 4*num_examples))\n",
    "    \n",
    "    correct_count = 0\n",
    "    incorrect_count = 0\n",
    "    example_idx = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(CONFIG['device']), targets.to(CONFIG['device'])\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            for i in range(len(targets)):\n",
    "                if (predicted[i] == targets[i] and correct_count < num_examples) or \\\n",
    "                   (predicted[i] != targets[i] and incorrect_count < num_examples):\n",
    "                    \n",
    "                    is_correct = predicted[i] == targets[i]\n",
    "                    \n",
    "                    if is_correct:\n",
    "                        correct_count += 1\n",
    "                    else:\n",
    "                        incorrect_count += 1\n",
    "                    \n",
    "                    img = inputs[i].cpu().numpy().transpose(1, 2, 0)\n",
    "                    mean = np.array([0.485, 0.456, 0.406])\n",
    "                    std = np.array([0.229, 0.224, 0.225])\n",
    "                    img = std * img + mean\n",
    "                    img = np.clip(img, 0, 1)\n",
    "                    \n",
    "                    plt.subplot(num_examples*2, 5, example_idx + 1)\n",
    "                    plt.imshow(img)\n",
    "                    plt.title(f\"True: {idx_to_class[targets[i].item()]}\\n\"\n",
    "                              f\"Pred: {idx_to_class[predicted[i].item()]}\\n\"\n",
    "                              f\"{'Correct' if is_correct else 'Incorrect'}\")\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    example_idx += 1\n",
    "            \n",
    "            if correct_count >= num_examples and incorrect_count >= num_examples:\n",
    "                break\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(CONFIG['plots_dir'], 'prediction_examples.png'))\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if CONFIG['resume_checkpoint'] is None:\n",
    "        latest_checkpoint = find_latest_checkpoint(CONFIG['checkpoint_dir'])\n",
    "        if latest_checkpoint:\n",
    "            print(f\"Found latest checkpoint: {latest_checkpoint}\")\n",
    "            CONFIG['resume_checkpoint'] = latest_checkpoint\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_model()\n",
    "    \n",
    "    best_model_path = os.path.join(CONFIG['checkpoint_dir'], 'best_model.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(\"Loading best model for prediction examples...\")\n",
    "        checkpoint = torch.load(best_model_path, map_location=CONFIG['device'])\n",
    "        \n",
    "        num_classes = len(checkpoint['class_mapping'])\n",
    "        model = create_model(num_classes)\n",
    "        model = model.to(CONFIG['device'])\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        _, _, test_loader, _ = get_datasets_and_loaders()\n",
    "        \n",
    "        plot_prediction_examples(model, test_loader, checkpoint['class_mapping'])\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    hours, remainder = divmod(total_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f\"\\nTotal execution time: {int(hours)}h {int(minutes)}m {int(seconds)}s\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
